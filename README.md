# üóëÔ∏è Trash Talk App ‚Äî Monorepo

This repository now houses the entire Trash Talk project: a Next.js frontend, a Flask inference backend, and the TensorFlow training pipeline that produces the model used for predictions.

## Repository Layout

- `frontend/` ‚Äì Next.js 14 + Tailwind UI for uploads, auth, dashboards, and visualizations.
- `backend/` ‚Äì Flask API that loads the latest `model/model.h5` file and exposes `/api/analyze`.
- `model-training/` ‚Äì TensorFlow/Keras training scripts, notebooks, and dataset helpers.
- `scripts/` ‚Äì cross-cutting utilities (e.g., `copy_model.py` to sync trained weights into the backend).

Legacy files from the original single Next.js project have been removed to avoid confusion.

## Getting Started

### 1. Frontend
```bash
cd frontend
npm install
npm run dev
# http://localhost:3000
```

Important env vars (create `frontend/.env.local`):
```
NEXT_PUBLIC_BACKEND_URL=http://localhost:5000
NEXT_PUBLIC_FIREBASE_API_KEY=...
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=...
NEXT_PUBLIC_FIREBASE_PROJECT_ID=...
NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=...
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=...
NEXT_PUBLIC_FIREBASE_APP_ID=...
```

### 2. Backend
```bash
cd backend
python -m venv venv
venv\Scripts\activate  # or source venv/bin/activate
pip install -r requirements.txt
python app.py           # http://localhost:5000
```

**Model Options:**
- **Option A (Recommended)**: Use alternative ML providers (no training needed!)
  - See `backend/ALTERNATIVE_ML_PROVIDERS.md` for setup
  - Set `ML_PROVIDER=huggingface` in your `.env` file (free tier available)
  
- **Option B**: Use custom trained model
  - Ensure `backend/model/model.h5` exists
  - Copy the latest trained model with: `python scripts/copy_model.py`

### 3. Model Training (optional - not required!)
**You don't need to train your own model!** Use alternative ML providers instead (see `backend/ALTERNATIVE_ML_PROVIDERS.md`).

If you want to train a custom model:
```bash
cd model-training
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python scripts/train_model.py
```

Datasets, checkpoints, and TensorBoard logs are git-ignored; follow `model-training/README.md` for download instructions. After training, run `python ../scripts/copy_model.py` from the repo root to sync the newest weights into the backend.

### Firebase Setup

1. In [Firebase Console](https://console.firebase.google.com/), create a project and add a Web App.
2. Enable **Authentication** (Email/Password) and **Cloud Firestore** (Start in production mode).
3. Enable **Cloud Storage**. The default bucket name becomes your `NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET`.
4. Update Storage security rules so authenticated users can read/write their own profile folder, e.g.:
   ```
   rules_version = '2';
   service firebase.storage {
     match /b/{bucket}/o {
       match /profiles/{userId}/{allPaths=**} {
         allow read, write: if request.auth != null && request.auth.uid == userId;
       }
     }
   }
   ```
5. Copy the web app configuration into `frontend/.env.local` using the variables listed above.
6. Restart `npm run dev` so the new env vars load.

With storage enabled, the profile page lets users upload an avatar; uploaded files land under `profiles/{uid}/avatar-<timestamp>` in your bucket, and the public URL is stored in Firestore.

### Changing a Profile Photo (End-User Flow)

1. Visit `/profile` while signed in.
2. Click the green **Change** pill under the avatar and pick an image (‚â§5‚ÄØMB). A local preview appears immediately.
3. Hit **Save Changes**. The UI will:
   - Upload the image to Firebase Storage under `profiles/{uid}/`.
   - Store the resulting download URL inside the `users/{uid}` Firestore document.
   - Reset the button once Firebase confirms both writes.
4. Reloading the page later pulls the saved `photoUrl`, so the same avatar shows on every visit. Users can repeat the steps at any time to replace the photo.

## Environmental Impact Calculation

The app calculates environmental impact metrics (water saved, trees equivalent, energy conserved) using **category-specific, research-backed values** stored in `frontend/lib/environmental-impact.ts`.

### Impact Metrics by Category

Each waste category has specific environmental impact multipliers based on EPA and EIA research:

- **Paper**: 5.0 L water, 0.003 trees, 2.5 kWh per item
- **Metal**: 3.0 L water, 0 trees, 3.5 kWh per item  
- **Glass**: 2.0 L water, 0 trees, 1.0 kWh per item
- **Plastic**: 1.5 L water, 0 trees, 1.8 kWh per item
- **Textiles**: 4.0 L water, 0 trees, 2.0 kWh per item
- **Organic Waste**: 0.5 L water, 0.001 trees, 0.3 kWh per item
- **Other**: 1.0 L water, 0 trees, 0.5 kWh per item

### Usage

```typescript
import { calculateEnvironmentalImpact, getCategoryImpact } from '@/lib/environmental-impact';

// Calculate total impact from user statistics
const impact = calculateEnvironmentalImpact(userStats);
// Returns: { waterSaved, treesEquivalent, energyConserved }

// Get impact for a specific category
const paperImpact = getCategoryImpact('Paper');
```

The dashboard automatically calculates cumulative impact based on the actual categories of items recycled, providing accurate and meaningful metrics.

## Development Tips

- Keep virtual environments, logs, uploads, datasets, and large binaries out of version control (already handled via `.gitignore`).
- Use `DEBUG_SUMMARY.md` and `CONNECTION_GUIDE.md` for troubleshooting notes and verifying the frontend ‚Üî backend flow.
- When adding new assets or directories that should exist empty (uploads, logs, etc.), drop a `.gitkeep` file so collaborators receive the structure.
- Environmental impact values are research-backed and documented in `frontend/lib/environmental-impact.ts` with source citations.

With this layout, each subsystem can evolve independently while sharing a single Git history. Let me know if you need additional automation (e.g., root scripts for running both servers).

